import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.utils import save_image
from tqdm import tqdm


class SAGANTrainer:
    """
    [1. TTUR(Two-Timescale Update Rule)]
    SAGAN ë…¼ë¬¸ì—ì„œëŠ” íŒë³„ìê°€ ë„ˆë¬´ ëŠë¦¬ê²Œ í•™ìŠµë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ìƒì„±ìë³´ë‹¤ íŒë³„ìì˜ í•™ìŠµë¥ (Learning Rate)ì„ ë” ë†’ê²Œ ì„¤ì •.
    ex) g_lr = 0.0001, d_lr = 0.0004

    [2. detach()]
    íŒë³„ìì˜ ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ lossë¥¼ ê³„ì‚°í•  ë•Œ, detachë¥¼ ì ìš©í•œ ì´ìœ ëŠ” íŒë³„ì í•™ìŠµì‹œ ìƒì„±ìì˜ ê°€ì¤‘ì¹˜ê¹Œì§€ ë¯¸ë¶„ê°’ì´ íë¥´ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•¨.
    """

    def __init__(self, generator, discriminator, dataloader, config):
        # ìƒìˆ˜ 
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        TRAIN = config["train"]
        self.sample_step = TRAIN["sample_step"]
        self.checkpoint_step = TRAIN["checkpoint_step"]

        MODEL = config["model"]
        self.latent_dim = MODEL["latent_dim"]

        PATH = config["path"]
        self.sample_dir = PATH["sample_dir"]
        self.checkpoint_dir = PATH["checkpoint_dir"]

        self.g = generator.to(self.device)
        self.d = discriminator.to(self.device)
        self.dataloader = dataloader 

        # TTUR(Two-Timescale Update Rule) ì ìš© 
        betas = (TRAIN["beta1"], TRAIN["beta2"])
        self.g_opt = optim.Adam(params=self.g.parameters(), lr=TRAIN["lr_g"], betas=betas)
        self.d_opt = optim.Adam(params=self.d.parameters(), lr=TRAIN["lr_d"], betas=betas)

        self.fixed_noise = torch.randn(32, self.latent_dim, 1, 1).to(self.device)

    def train(self, epochs: int):
        for epoch in range(epochs):
            progress_bar = tqdm(enumerate(self.dataloader),
                                total=len(self.dataloader),
                                desc=f"Epoch [{epoch + 1} / {epochs}]")

            for i, (real_imgs, _) in progress_bar:
                real_imgs = real_imgs.to(self.device)
                b_size = real_imgs.size(0)
                sample_dir = os.path.abspath(os.path.join(os.getcwd(), self.sample_dir))

                if i == 0: # ì—í¬í¬ ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í™•ì¸
                    real_sample_path = os.path.join(sample_dir, f"real_epoch_{epoch + 1}.png")
                    # ì‹¤ì œ ë°ì´í„°ì…‹ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•´ì„œ ëˆˆìœ¼ë¡œ í™•ì¸
                    save_image(real_imgs[:32], real_sample_path, normalize=True, value_range=(-1, 1))

                # ============ íŒë³„ì í•™ìŠµ =============
                self.d_opt.zero_grad()

                # ì§„ì§œ ì´ë¯¸ì§€ ì†ì‹¤ (Hinge Loss)
                # - íŒë³„ìì— Label Smoothing ì ìš© (ë¬´ì¡°ê±´ 100% ê°€ì§œë¼ê³  í™•ì‹ í•˜ì§€ ëª»í•˜ê²Œ í•¨)
                # - í›ˆë ¨ê³¼ì •ì—ì„œ D_LOSSê°€ 0.0ì— ìˆ˜ë ´í•˜ì—¬ íŒë³„ìê°€ ì™„ë²½í•˜ê²Œ êµ¬ë¶„í•œë‹¤ë©´ ìƒì„±ì ì…ì¥ì—ì„œëŠ” ê¸°ìš¸ê¸°(Gradient)ë¥¼ ì „í˜€ ë°›ì§€ ëª»í•¨.
                # - ë”°ë¼ì„œ ì•„ë¬´ë¦¬ í•™ìŠµì„ í•´ë„ ì‹¤ë ¥ì´ ëŠ˜ì§€ ì•ŠëŠ” ê¸°ìš¸ê¸° ì†Œì‹¤(Gradient Vanishing) ìƒíƒœì— ë¹ ì§.
                d_out_real = self.d(real_imgs)
                d_loss_real = nn.ReLU()(1.0 - d_out_real).mean()

                # ê°€ì§œ ì´ë¯¸ì§€ ì†ì‹¤ 
                z = torch.randn(b_size, self.latent_dim).to(self.device)
                fake_imgs = self.g(z)
                d_out_fake = self.d(fake_imgs.detach())
                d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()

                d_loss = (d_loss_real + d_loss_fake) / 2

                d_loss.backward()
                self.d_opt.step()

                # ============ ìƒì„±ì í•™ìŠµ ==============
                # D_LOSS = 0 ë¬¸ì œ(íŒë³„ì ìŠ¹ë¦¬ ë¬¸ì œ) í•´ê²°ì„ ìœ„í•´ në²ˆì”© ìƒì„±ì í›ˆë ¨  
                for _ in range(2):
                    self.g_opt.zero_grad()

                    # ê°€ì§œ ì´ë¯¸ì§€ë¥¼ íŒë³„ìê°€ ì§„ì§œë¡œ ë¯¿ê²Œ ë§Œë“¤ê¸° 
                    z = torch.randn(b_size, self.latent_dim).to(self.device)
                    fake_imgs_new = self.g(z)

                    g_out_fake = self.d(fake_imgs_new)
                    g_loss = -g_out_fake.mean()

                    g_loss.backward()
                    self.g_opt.step()

                # tqdm ì§„í–‰ë°” ì˜¤ë¥¸ìª½ì— ì‹¤ì‹œê°„ Loss ê°’ í‘œì‹œ 
                progress_bar.set_postfix({
                    "D_LOSS": f"{d_loss.item():.4f}",
                    "G_LOSS": f"{g_loss.item():.4f}"
                })
            
            # ê³ ì • ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ìƒì„± 
            fixed_noise_path = os.path.join(sample_dir, f"fixed_noise_{epoch + 1}.png")
            random_noise_path = os.path.join(sample_dir, f"random_noise_{epoch + 1}.png")

            self.g.eval()
            with torch.no_grad():
                # ê³ ì • ë…¸ì´ì¦ˆ ì´ë¯¸ì§€
                fake_img = self.g(self.fixed_noise).detach().cpu()
                save_image(fake_img, fixed_noise_path, normalize=True, value_range=(-1, 1))

                # ëœë¤ ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ 
                z = torch.randn(32, self.latent_dim).to(self.device)
                fake_img_random = self.g(z).detach().cpu()
                save_image(fake_img_random, random_noise_path, normalize=True, value_range=(-1, 1))
            self.g.train()

            if (epoch + 1) % self.checkpoint_step == 0:
                self.save_checkpoint(epoch)

            print(f"Gamma-G {self.get_gamma_values(self.g)}")
            print(f"Gamma-D {self.get_gamma_values(self.d)}")

    def load_checkpoint(self, path):
        """ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° í•™ìŠµ ì¬ê°œ"""
        print(f"ğŸ”„ Loading checkpoint from {path}...")
        checkpoint = torch.load(path, map_location=self.device)
        
        self.g.load_state_dict(checkpoint['g_state_dict'])
        self.d.load_state_dict(checkpoint['d_state_dict'])
        self.g_opt.load_state_dict(checkpoint['g_opt_state_dict'])
        self.d_opt.load_state_dict(checkpoint['d_opt_state_dict'])
        
        return checkpoint['epoch']
        
    def save_checkpoint(self, epoch):
        """
        ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ì €ì¥ 
        """
        checkpoint_dir = os.path.abspath(os.path.join(os.getcwd(), self.checkpoint_dir))
        if not os.path.exists(checkpoint_dir):
            os.makedirs(checkpoint_dir)

        # ì €ì¥í•  ìƒíƒœ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± 
        state = {
            "epoch": epoch,
            "g_state_dict": self.g.state_dict(),
            "d_state_dict": self.d.state_dict(),
            "g_opt_state_dict": self.g_opt.state_dict(),
            "d_opt_state_dict": self.d_opt.state_dict(),
            "gamma_g": self.get_gamma_values(self.g),
            "gamma_d": self.get_gamma_values(self.d)
        }

        path = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth")
        torch.save(state, path)
        print(f"Epoch {epoch + 1} - Checkpoint Saved: {path}")

    def get_gamma_values(self, model):
        gammas = []
        for name, param in model.named_parameters():
            if "gamma" in name:
                gammas.append(param.item())

        return gammas